{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5350e50b-62a6-4665-9982-088d7a47f28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.linalg as tla\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numml.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47429021-b9bc-4b6d-87e6-bb52a82e01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our favorite poisson operator\n",
    "\n",
    "N = 9\n",
    "A = sp.eye(N)*2. - sp.eye(N, k=1) - sp.eye(N, k=-1)\n",
    "b = torch.zeros(N)\n",
    "b[N//2] = 1.\n",
    "print(A.to_dense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1740c16-9b1d-48cc-9385-e883c3d2627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tentative aggregation operator\n",
    "\n",
    "Agg = torch.Tensor([\n",
    "    [1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
    "]).T\n",
    "Agg = sp.SparseCSRTensor(Agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d91e5f9-5bf1-4ea2-a18f-7f7493e27eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize a smoother for the agg op\n",
    "\n",
    "S = A.copy()\n",
    "S_orig = S.copy()\n",
    "S.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127d02a4-709f-471b-9bad-a85925d9cec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multigrid cycle and jacobi smoother\n",
    "\n",
    "def jacobi(A, x, b, omega=0.6):\n",
    "    Dinv = sp.diag(1./A.diagonal())\n",
    "    return omega * (Dinv @ b) + (sp.eye(A.shape[0]) - omega * (Dinv@A)) @ x\n",
    "\n",
    "def mgrid(P, A, x, b):\n",
    "    x = jacobi(A, x, b)\n",
    "    r_H = P.T @ (b - A @ x)\n",
    "    A_H = P.T @ A @ P\n",
    "    x = x + P @ sp.spsolve(A_H, r_H)\n",
    "    x = jacobi(A, x, b)\n",
    "    return x\n",
    "\n",
    "def mgrid_solver(P, A, x, b, iterations=100):\n",
    "    res_history = torch.zeros(iterations)\n",
    "    res_history[0] = tla.norm(b-A@x)/tla.norm(b)\n",
    "    \n",
    "    for i in range(1, iterations):\n",
    "        x = mgrid(P, A, x, b)\n",
    "        res_history[i] = tla.norm(b-A@x)/tla.norm(b)\n",
    "    return res_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8480199a-84f1-4b30-b186-eb58e89641cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our starting initial guess to A^{-1}, which we'll initialize to A^T\n",
    "\n",
    "Ainv = A.T@A\n",
    "Ainv.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c410ca3-ff6c-45df-bd6a-32ff53f1dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize over the entries of S to create an optimal smoother\n",
    "# we'll use a few multigrid iterations for the loss\n",
    "\n",
    "optimizer = torch.optim.Adam([S.data], lr=0.1)\n",
    "batch = 20\n",
    "mgrid_it = 3\n",
    "lh = []\n",
    "\n",
    "x_test = torch.randn(batch, N)\n",
    "x_test /= tla.norm(x_test, dim=0)\n",
    "\n",
    "for i in range(5_000):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Compute smoother\n",
    "    P = S @ Agg\n",
    "    \n",
    "    loss = 0.\n",
    "    for j in range(batch):\n",
    "        # Random initial guess and a few multigrid iterations\n",
    "        x0 = x_test[j]\n",
    "        x1 = x0\n",
    "        for k in range(mgrid_it):\n",
    "            x1 = mgrid(P, A, x1, b)\n",
    "\n",
    "        # compute loss as rel residual of x / rel residual of x0\n",
    "        r0 = tla.norm(b-A@x0) / tla.norm(b)\n",
    "        r1 = tla.norm(b-A@x1) / tla.norm(b)\n",
    "\n",
    "        loss += (r1 / r0) / batch\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    lh.append(loss.item())\n",
    "    if i % 10 == 0:\n",
    "        print(i, 'loss:', loss.item())\n",
    "    if loss.item() < 0.007:\n",
    "        print(i, 'loss:', loss.item())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732a2600-ae83-468c-a9d0-f970919d53f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lh = np.array(lh)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(Lh, 'k')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90949636-3c22-4aee-b2db-6351db43b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run our candidate smoothers on a random guess\n",
    "\n",
    "x0 = torch.randn(N); x0 /= tla.norm(x0)\n",
    "\n",
    "orig_res = None\n",
    "opt_res = None\n",
    "\n",
    "with torch.no_grad():\n",
    "    orig_res = mgrid_solver((sp.eye(N) - 0.4*A) @ Agg, A, x0, b)\n",
    "    opt_res = mgrid_solver(S @ Agg, A, x0, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa10abfb-6bc0-4eb5-922d-e5d699336e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Comparison of smoothers')\n",
    "plt.semilogy(orig_res[:10], label='S = A')\n",
    "plt.semilogy(opt_res[:10], label='Optimized S')\n",
    "plt.grid()\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('$\\|b - Ax\\| / \\|b\\|$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b5294e-e53c-47b7-b27e-0a551c117e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
